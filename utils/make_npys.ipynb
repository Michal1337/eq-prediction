{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-29 03:27:45.344194: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-29 03:27:46.895749: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import tqdm\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1337\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_DATE_TRAIN = \"2018-09-14\" # df[\"time\"].quantile(0.8)\n",
    "SPLIT_DATE_VAL = \"2020-12-03\" # df[\"time\"].quantile(0.9)\n",
    "BLOCK_SIZE = 128\n",
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/with_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>depth</th>\n",
       "      <th>mag</th>\n",
       "      <th>time_new</th>\n",
       "      <th>latitude_disc</th>\n",
       "      <th>longitude_disc</th>\n",
       "      <th>pos</th>\n",
       "      <th>diff_days</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1973-02-01 01:33:03.700</td>\n",
       "      <td>167.1750</td>\n",
       "      <td>-15.5650</td>\n",
       "      <td>45.000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1973-02-01</td>\n",
       "      <td>-16</td>\n",
       "      <td>167</td>\n",
       "      <td>-16_167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1973-02-15 16:40:55.500</td>\n",
       "      <td>167.1410</td>\n",
       "      <td>-15.1390</td>\n",
       "      <td>64.000</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1973-02-01</td>\n",
       "      <td>-16</td>\n",
       "      <td>167</td>\n",
       "      <td>-16_167</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1973-03-27 20:55:27.900</td>\n",
       "      <td>167.2960</td>\n",
       "      <td>-15.0080</td>\n",
       "      <td>135.000</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1973-03-01</td>\n",
       "      <td>-16</td>\n",
       "      <td>167</td>\n",
       "      <td>-16_167</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1973-04-08 13:41:02.000</td>\n",
       "      <td>167.2180</td>\n",
       "      <td>-15.7790</td>\n",
       "      <td>35.000</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1973-04-01</td>\n",
       "      <td>-16</td>\n",
       "      <td>167</td>\n",
       "      <td>-16_167</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1973-04-21 21:30:35.700</td>\n",
       "      <td>167.2830</td>\n",
       "      <td>-15.8820</td>\n",
       "      <td>33.000</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1973-04-01</td>\n",
       "      <td>-16</td>\n",
       "      <td>167</td>\n",
       "      <td>-16_167</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972926</th>\n",
       "      <td>2023-01-24 06:52:23.260</td>\n",
       "      <td>-97.8194</td>\n",
       "      <td>37.2064</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>37</td>\n",
       "      <td>-98</td>\n",
       "      <td>37_-98</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972927</th>\n",
       "      <td>2023-02-11 03:29:01.909</td>\n",
       "      <td>-97.8680</td>\n",
       "      <td>37.5394</td>\n",
       "      <td>5.000</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>37</td>\n",
       "      <td>-98</td>\n",
       "      <td>37_-98</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972928</th>\n",
       "      <td>2023-02-26 06:48:59.171</td>\n",
       "      <td>-97.2213</td>\n",
       "      <td>37.7068</td>\n",
       "      <td>2.198</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2023-02-01</td>\n",
       "      <td>37</td>\n",
       "      <td>-98</td>\n",
       "      <td>37_-98</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972929</th>\n",
       "      <td>2023-03-05 20:35:51.407</td>\n",
       "      <td>-97.8587</td>\n",
       "      <td>37.0150</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2023-03-01</td>\n",
       "      <td>37</td>\n",
       "      <td>-98</td>\n",
       "      <td>37_-98</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972930</th>\n",
       "      <td>2023-04-19 05:20:03.946</td>\n",
       "      <td>-97.1059</td>\n",
       "      <td>37.6186</td>\n",
       "      <td>0.563</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>37</td>\n",
       "      <td>-98</td>\n",
       "      <td>37_-98</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3972931 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            time  longitude  latitude    depth  mag  \\\n",
       "0        1973-02-01 01:33:03.700   167.1750  -15.5650   45.000  5.0   \n",
       "1        1973-02-15 16:40:55.500   167.1410  -15.1390   64.000  4.8   \n",
       "2        1973-03-27 20:55:27.900   167.2960  -15.0080  135.000  4.9   \n",
       "3        1973-04-08 13:41:02.000   167.2180  -15.7790   35.000  6.4   \n",
       "4        1973-04-21 21:30:35.700   167.2830  -15.8820   33.000  5.3   \n",
       "...                          ...        ...       ...      ...  ...   \n",
       "3972926  2023-01-24 06:52:23.260   -97.8194   37.2064    5.000  2.6   \n",
       "3972927  2023-02-11 03:29:01.909   -97.8680   37.5394    5.000  3.2   \n",
       "3972928  2023-02-26 06:48:59.171   -97.2213   37.7068    2.198  2.3   \n",
       "3972929  2023-03-05 20:35:51.407   -97.8587   37.0150    5.000  2.2   \n",
       "3972930  2023-04-19 05:20:03.946   -97.1059   37.6186    0.563  2.3   \n",
       "\n",
       "           time_new  latitude_disc  longitude_disc      pos  diff_days  label  \n",
       "0        1973-02-01            -16             167  -16_167        NaN      0  \n",
       "1        1973-02-01            -16             167  -16_167       14.0      0  \n",
       "2        1973-03-01            -16             167  -16_167       40.0      1  \n",
       "3        1973-04-01            -16             167  -16_167       11.0      1  \n",
       "4        1973-04-01            -16             167  -16_167       13.0      1  \n",
       "...             ...            ...             ...      ...        ...    ...  \n",
       "3972926  2023-01-01             37             -98   37_-98       37.0      0  \n",
       "3972927  2023-02-01             37             -98   37_-98       17.0      0  \n",
       "3972928  2023-02-01             37             -98   37_-98       15.0      0  \n",
       "3972929  2023-03-01             37             -98   37_-98        7.0      0  \n",
       "3972930  2023-04-01             37             -98   37_-98       44.0      1  \n",
       "\n",
       "[3972931 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df, SPLIT_DATE_TRAIN):\n",
    "    scaler_dict = {}\n",
    "    df_train = df[df[\"time_new\"] < SPLIT_DATE_TRAIN]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df_train[\"mag\"].values.reshape(-1, 1))\n",
    "    df[\"mag\"] = scaler.transform(df[\"mag\"].values.reshape(-1, 1))\n",
    "    scaler_dict[\"mag\"] = scaler\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    depth = np.log(df_train[\"depth\"] + np.abs(df_train[\"depth\"].min()) + 1).values.reshape(-1, 1)\n",
    "    scaler.fit(depth)\n",
    "    df[\"depth\"] = scaler.transform(df[\"depth\"].values.reshape(-1, 1))\n",
    "    scaler_dict[\"depth\"] = scaler\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    diff_days = np.log(df_train[\"diff_days\"] + 1).values.reshape(-1, 1)\n",
    "    scaler.fit(diff_days)\n",
    "    df[\"diff_days\"] = scaler.transform(df[\"diff_days\"].values.reshape(-1, 1))\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_train[\"latitude\"].values.reshape(-1, 1))\n",
    "    df[\"latitude\"] = scaler.transform(df[\"latitude\"].values.reshape(-1, 1))\n",
    "    scaler_dict[\"latitude\"] = scaler\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_train[\"longitude\"].values.reshape(-1, 1))\n",
    "    df[\"longitude\"] = scaler.transform(df[\"longitude\"].values.reshape(-1, 1))\n",
    "    scaler_dict[\"longitude\"] = scaler\n",
    "    return df, scaler_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_block(df, block_size):\n",
    "    for idx in range(1, block_size):\n",
    "        df[\"mag_\" + str(idx)] = df[\"mag\"].shift(idx)\n",
    "        df[\"depth_\" + str(idx)] = df[\"depth\"].shift(idx)\n",
    "        df[\"latitude_\" + str(idx)] = df[\"latitude\"].shift(idx)\n",
    "        df[\"longitude_\" + str(idx)] = df[\"longitude\"].shift(idx)\n",
    "        df[\"diff_days_\" + str(idx)] = df[\"diff_days\"].shift(idx)\n",
    "    df.dropna(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, block_size, feature_order):\n",
    "    x_train = df[feature_order].to_numpy().reshape(-1, block_size, len(feature_order) // block_size)\n",
    "    y_train = df[\"label\"].to_numpy().reshape(-1, 1)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_all(df, block_size, feature_order, SPLIT_DATE_TRAIN, SPLIT_DATE_VAL):\n",
    "    df_train = df[df[\"time\"] < SPLIT_DATE_TRAIN]\n",
    "    df_val = df[(df[\"time\"] >= SPLIT_DATE_TRAIN) & (df[\"time\"] < SPLIT_DATE_VAL)]\n",
    "    df_test = df[df[\"time\"] >= SPLIT_DATE_VAL]\n",
    "    x_train, y_train = split(df_train, block_size, feature_order)\n",
    "    x_val, y_val = split(df_val, block_size, feature_order)\n",
    "    x_test, y_test = split(df_test, block_size, feature_order)\n",
    "    return x_train, y_train, x_val, y_val, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "featrues = [\"mag\", \"depth\", \"latitude\", \"longitude\", \"diff_days\"]\n",
    "featrues_order = [featrues[idx] + \"_\" + str(i) for i in range(BLOCK_SIZE-1, 0, -1) for idx in range(len(featrues))]\n",
    "featrues_order = featrues_order + featrues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_npys(df, block_size, features_order, SPLIT_DATE_TRAIN, SPLIT_DATE_VAL):\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"], format=\"mixed\")\n",
    "    df.sort_values(by=\"time\", inplace=True)\n",
    "    df, scaler_dict = preprocess_df(df, SPLIT_DATE_TRAIN)\n",
    "    \n",
    "    for idx, pos in enumerate(tqdm.tqdm(df[\"pos\"].unique())):\n",
    "        df_pos = df[df[\"pos\"] == pos]\n",
    "        df_pos = make_block(df_pos, block_size)\n",
    "        x_train, y_train, x_val, y_val, x_test, y_test = split_all(df_pos, block_size, features_order, SPLIT_DATE_TRAIN, SPLIT_DATE_VAL)\n",
    "        np.save(\"../data/npys/x_train_\" + str(idx) + \".npy\", x_train)\n",
    "        np.save(\"../data/npys/y_train_\" + str(idx) + \".npy\", y_train)\n",
    "        np.save(\"../data/npys/x_val_\" + str(idx) + \".npy\", x_val)\n",
    "        np.save(\"../data/npys/y_val_\" + str(idx) + \".npy\", y_val)\n",
    "        np.save(\"../data/npys/x_test_\" + str(idx) + \".npy\", x_test)\n",
    "        np.save(\"../data/npys/y_test_\" + str(idx) + \".npy\", y_test)\n",
    "    return scaler_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1349/1349 [24:56<00:00,  1.11s/it] \n"
     ]
    }
   ],
   "source": [
    "scalers = make_npys(df.copy(deep=True), BLOCK_SIZE, featrues_order, SPLIT_DATE_TRAIN, SPLIT_DATE_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers\n",
    "with open(\"../data/scalers_for_npys.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scalers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
